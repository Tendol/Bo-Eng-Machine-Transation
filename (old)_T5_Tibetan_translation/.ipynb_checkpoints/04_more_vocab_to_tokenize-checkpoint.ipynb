{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "from tokenizers import SentencePieceBPETokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import SparseAdam\n",
    "from transformers import (\n",
    "    T5Model, \n",
    "    T5ForConditionalGeneration, \n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import pytorch_lightning as pl\n",
    "import time\n",
    "from datetime import datetime\n",
    "import textwrap\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boDataForTokenizerPath = '../data/all_bo.txt'\n",
    "enDataForTokenizerPath = '../data/all_en.txt'\n",
    "\n",
    "boDataPath = '../data/train.bo'\n",
    "enDataPath = '../data/train.en'\n",
    "\n",
    "boTokenizerPath = '../preProcessing/bo.model'\n",
    "enTokenizerPath = '../preProcessing/en.model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bo</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>རྒྱལ་པོ་ཞེས་བྱ་བས་རྒྱལ་སྲིད་འབྱོར་པ་རྒྱས་པ་བདེ...</td>\n",
       "      <td>under his rule the kingdom prospered and thriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>དེས་དཔུང་གི་ཚོགས་ཡན་ལག་བཞི་པ་གླང་པོ་ཆེ་པའི་ཚོག...</td>\n",
       "      <td>he called up the four branches of his armed fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>སུམ་ཅུ་རྩ་གསུམ་པའི་ལྷ་རྣམས་ཀྱི་ཁ་དོག་གི་མཐུ་བས...</td>\n",
       "      <td>bathed in a vast light more luminous than the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>མ་མ་བརྒྱད་པོ་པང་ན་འཚོ་བའི་མ་མ་གཉིས་དང་ནུ་མ་སྣུ...</td>\n",
       "      <td>was entrusted to eight nursemaids two to cuddl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>རྒྱལ་པོ་རྒྱལ་རིགས་སྤྱི་བོར་དབང་བསྐུར་བ་ལྗོངས་ཀ...</td>\n",
       "      <td>he trained in and mastered those arts and skil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106861</th>\n",
       "      <td>མད་གལ་གྱི་བུ་དེ་བཞིན་གཤེགས་པ་དགྲ་བཅོམ་པ་ཡང་དག་...</td>\n",
       "      <td>maudgalyayana the thusgone worthy perfect budd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106862</th>\n",
       "      <td>བཅོམ་ལྡན་འདས་ཀྱིས་དེ་སྐད་ཅེས་བཀའ་སྩལ་པ་དང་་ཚེ་...</td>\n",
       "      <td>when the blessed one had spoken venerable maha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106863</th>\n",
       "      <td>འཕགས་པ་བཅོམ་ལྡན་འདས་ཀྱི་ཡེ་ཤེས་རྒྱས་པའི་མདོ་སྡ...</td>\n",
       "      <td>this completes the great vehicle sutra the pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106864</th>\n",
       "      <td>རྒྱ་གར་གྱི་མཁན་པོ་པྲཛྙ་བར་མ་དང་་ལོཙྪ་བ་བན་དེ་ཡ...</td>\n",
       "      <td>this was translated by the indian preceptor pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106865</th>\n",
       "      <td>རྒྱ་གར་གྱི་མཁན་པོ་བི་ཤུད་དྷ་སིང་ཧ་དང་་སརྦ་ཛྙ་ད...</td>\n",
       "      <td>the text was later edited and finalized by the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106866 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       bo  \\\n",
       "0       རྒྱལ་པོ་ཞེས་བྱ་བས་རྒྱལ་སྲིད་འབྱོར་པ་རྒྱས་པ་བདེ...   \n",
       "1       དེས་དཔུང་གི་ཚོགས་ཡན་ལག་བཞི་པ་གླང་པོ་ཆེ་པའི་ཚོག...   \n",
       "2       སུམ་ཅུ་རྩ་གསུམ་པའི་ལྷ་རྣམས་ཀྱི་ཁ་དོག་གི་མཐུ་བས...   \n",
       "3       མ་མ་བརྒྱད་པོ་པང་ན་འཚོ་བའི་མ་མ་གཉིས་དང་ནུ་མ་སྣུ...   \n",
       "4       རྒྱལ་པོ་རྒྱལ་རིགས་སྤྱི་བོར་དབང་བསྐུར་བ་ལྗོངས་ཀ...   \n",
       "...                                                   ...   \n",
       "106861  མད་གལ་གྱི་བུ་དེ་བཞིན་གཤེགས་པ་དགྲ་བཅོམ་པ་ཡང་དག་...   \n",
       "106862  བཅོམ་ལྡན་འདས་ཀྱིས་དེ་སྐད་ཅེས་བཀའ་སྩལ་པ་དང་་ཚེ་...   \n",
       "106863  འཕགས་པ་བཅོམ་ལྡན་འདས་ཀྱི་ཡེ་ཤེས་རྒྱས་པའི་མདོ་སྡ...   \n",
       "106864  རྒྱ་གར་གྱི་མཁན་པོ་པྲཛྙ་བར་མ་དང་་ལོཙྪ་བ་བན་དེ་ཡ...   \n",
       "106865  རྒྱ་གར་གྱི་མཁན་པོ་བི་ཤུད་དྷ་སིང་ཧ་དང་་སརྦ་ཛྙ་ད...   \n",
       "\n",
       "                                                       en  \n",
       "0       under his rule the kingdom prospered and thriv...  \n",
       "1       he called up the four branches of his armed fo...  \n",
       "2       bathed in a vast light more luminous than the ...  \n",
       "3       was entrusted to eight nursemaids two to cuddl...  \n",
       "4       he trained in and mastered those arts and skil...  \n",
       "...                                                   ...  \n",
       "106861  maudgalyayana the thusgone worthy perfect budd...  \n",
       "106862  when the blessed one had spoken venerable maha...  \n",
       "106863  this completes the great vehicle sutra the pre...  \n",
       "106864  this was translated by the indian preceptor pr...  \n",
       "106865  the text was later edited and finalized by the...  \n",
       "\n",
       "[106866 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boFile = open(boDataPath, 'r', encoding = 'utf-8')\n",
    "enFile = open(enDataPath, 'r', encoding = 'utf-8')\n",
    "\n",
    "dataMatrix = []\n",
    "\n",
    "while True: \n",
    "    boLine = boFile.readline().strip()\n",
    "    enLine = enFile.readline().strip()\n",
    "    if not boLine or not enLine: \n",
    "        break \n",
    "    dataMatrix.append([boLine, enLine])\n",
    "  \n",
    "# Create pandas dataframe \n",
    "df = pd.DataFrame(dataMatrix, columns = ['bo', 'en'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boTextsAll = df['bo'].tolist()\n",
    "enTextsAll = df['en'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers for Tibetan and English\n",
    "\n",
    "The code cell below uses Google SentencePiece tokenizer, but we cannot yet figure out how to truncate and pad the tokenizations to the same length, nor the special characters. Save the code but we will not use it for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['▁ངའི་', 'མིང་ལ་', 'བསྟན་', 'སྒྲོལ་མ་', 'ཟེར་']]\n",
      "[[3644, 18002, 530, 6257, 2154], [4, 3333, 0, 6081, 3, 6750, 1030, 2261, 1961, 0]]\n",
      "ཆོས་སྟོན་ཏོ་་རང་གི་ལ་ཡོད་པའི་ ཨིན་ཡུལ་དང་ལྡན་པའི་\n",
      "ངའི་མིང་ལ་བསྟན་སྒྲོལ་མ་ཟེར་\n",
      "Vocab size of Tibetan Tokenizer: 32000\n",
      "[['▁My', '▁name', '▁is', 'n', \"'\", 't', '▁Tenzin', '▁Dolma', '▁Gyalpo']]\n",
      "[[8803, 180, 12, 5519, 15171, 17894], [887, 21491]]\n",
      "['My name is Tenzin Dolma Gyalpo', 'Hello']\n",
      "Vocab size of English Tokenizer: 25000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "## Ignore this cell\n",
    "'''\n",
    "\n",
    "# Load tokenizers that are already trained\n",
    "boTokenizer = spm.SentencePieceProcessor(model_file=boTokenizerPath)\n",
    "enTokenizer = spm.SentencePieceProcessor(model_file=enTokenizerPath)\n",
    "\n",
    "# Verify for Tibetan\n",
    "print(boTokenizer.encode(['ངའི་མིང་ལ་བསྟན་སྒྲོལ་མ་ཟེར་'], out_type=str))\n",
    "print(boTokenizer.encode(['ངའི་མིང་ལ་བསྟན་སྒྲོལ་མ་ཟེར་', 'བཀ྄ྲ་ཤིས་བདེ་ལེགས།'], out_type=int))\n",
    "print(boTokenizer.decode([4149, 306, 6, 245, 4660, 748]))\n",
    "print(boTokenizer.decode(['▁ངའི་', 'མིང་', 'ལ་', 'བསྟན་', 'སྒྲོལ་མ་', 'ཟེར་']))\n",
    "print('Vocab size of Tibetan Tokenizer:', boTokenizer.get_piece_size())\n",
    "\n",
    "# Verify for English\n",
    "print(enTokenizer.encode([\"My name isn't Tenzin Dolma Gyalpo\"], out_type=str))\n",
    "print(enTokenizer.encode(['My name is Tenzin Dolma Gyalpo', 'Hello'], out_type=int))\n",
    "print(enTokenizer.decode([[8803, 180, 12, 5519, 15171, 17894], [887, 21491]]))\n",
    "print('Vocab size of English Tokenizer:', enTokenizer.get_piece_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we use huggingface tokenizer now. The bad news is we can no longer find the right API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tibetan tokenizer vocab size: 32000\n",
      "English tokenizer vocab size: 32000\n"
     ]
    }
   ],
   "source": [
    "boTokenizer = SentencePieceBPETokenizer()\n",
    "boTokenizer.train([boDataForTokenizerPath], vocab_size = 32000, special_tokens = ['<s>', '<pad>', '</s>', '<unk>', '<mask>'])\n",
    "\n",
    "enTokenizer = SentencePieceBPETokenizer()\n",
    "enTokenizer.train([enDataForTokenizerPath], vocab_size = 32000, special_tokens = ['<s>', '<pad>', '</s>', '<unk>', '<mask>'])\n",
    "\n",
    "print('Tibetan tokenizer vocab size:', boTokenizer.get_vocab_size())\n",
    "print('English tokenizer vocab size:', enTokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: [6068, 753, 8639, 4042, 16876]\n",
      "token: ['▁ངའི་', 'མིང་', 'ལ་བསྟན་', 'སྒྲོལ་', 'མ་ཟེར་']\n",
      "mask: [1, 1, 1, 1, 1]\n",
      "ids: [6068, 753, 8639, 4042, 16876]\n",
      "token: ['▁ངའི་', 'མིང་', 'ལ་བསྟན་', 'སྒྲོལ་', 'མ་ཟེར་']\n",
      "mask: [1, 1, 1, 1, 1]\n",
      "ids: [10148, 1225, 2234, 162]\n",
      "token: ['▁བཀྲ་ཤིས་', 'བདེ་', 'ལེ', 'གས']\n",
      "mask: [1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Verify for Tibetan\n",
    "outputs = boTokenizer.encode_batch(['ངའི་མིང་ལ་བསྟན་སྒྲོལ་མ་ཟེར་', 'ངའི་མིང་ལ་བསྟན་སྒྲོལ་མ་ཟེར་', 'བཀ྄ྲ་ཤིས་བདེ་ལེགས།'])\n",
    "\n",
    "for output in outputs: \n",
    "    print('ids:', output.ids)\n",
    "    print('token:', output.tokens)\n",
    "    print('mask:', output.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: [20490, 1222, 169, 78, 12, 84, 16640, 27027, 221, 12146, 4043]\n",
      "token: ['▁My', '▁name', '▁is', 'n', \"'\", 't', '▁Tenzin', '▁Dol', 'ma', '▁Gyal', 'po']\n",
      "mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "ids: [20490, 1222, 169, 16640, 27027, 221, 12146, 4043]\n",
      "token: ['▁My', '▁name', '▁is', '▁Tenzin', '▁Dol', 'ma', '▁Gyal', 'po']\n",
      "mask: [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "ids: [961, 786, 79]\n",
      "token: ['▁H', 'ell', 'o']\n",
      "mask: [1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Verify for English\n",
    "outputs = enTokenizer.encode_batch([\"My name isn't Tenzin Dolma Gyalpo\", 'My name is Tenzin Dolma Gyalpo', 'Hello'])\n",
    "\n",
    "for output in outputs: \n",
    "    print('ids:', output.ids)\n",
    "    print('token:', output.tokens)\n",
    "    print('mask:', output.attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): \n",
    "    def __init__(self, boTexts, enTexts, boTokenizer, enTokenizer, boMaxLen, enMaxLen): \n",
    "        super().__init__()\n",
    "        self.boTexts = boTexts\n",
    "        self.enTexts = enTexts\n",
    "        self.boTokenizer = boTokenizer\n",
    "        self.enTokenizer = enTokenizer\n",
    "        \n",
    "        # Enable padding and truncation \n",
    "        self.boTokenizer.enable_padding(length = boMaxLen)\n",
    "        self.boTokenizer.enable_truncation(max_length = boMaxLen)\n",
    "        self.enTokenizer.enable_padding(length = enMaxLen)\n",
    "        self.enTokenizer.enable_truncation(max_length = enMaxLen)\n",
    "        \n",
    "    ''' Return the size of dataset '''\n",
    "    def __len__(self): \n",
    "        return len(self.boTexts)\n",
    "    \n",
    "    '''\n",
    "    -- The routine for querying one data entry \n",
    "    -- The index of must be specified as an argument\n",
    "    -- Return a dictionary \n",
    "    '''\n",
    "    def __getitem__(self, idx): \n",
    "        # Apply tokenizer\n",
    "        boOutputs = self.boTokenizer.encode(self.boTexts[idx])\n",
    "        enOutputs = self.enTokenizer.encode(self.enTexts[idx])\n",
    "        \n",
    "        # Get numerical tokens \n",
    "        boEncoding = boOutputs.ids\n",
    "        enEncoding = enOutputs.ids\n",
    "        \n",
    "        # Get attention mask \n",
    "        boMask = boOutputs.attention_mask\n",
    "        enMask = enOutputs.attention_mask\n",
    "        \n",
    "        return {\n",
    "            'source_ids': torch.tensor(boEncoding), \n",
    "            'source_mask': torch.tensor(boMask), \n",
    "            'target_ids': torch.tensor(enEncoding), \n",
    "            'target_mask': torch.tensor(enMask)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule): \n",
    "    ''' Part 1: Define the architecture of model in init '''\n",
    "    def __init__(self, hparams):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            hparams['pretrainedModelName'], \n",
    "            return_dict = True    # I set return_dict true so that outputs  are presented as dictionaries\n",
    "        )\n",
    "        self.boTokenizer = hparams['boTokenizer']\n",
    "        self.enTokenizer = hparams['enTokenizer']\n",
    "        self.hparams = hparams\n",
    "        self.scheduler_is_created = False\n",
    "        \n",
    "        \n",
    "    ''' Part 2: Define the forward propagation '''\n",
    "    def forward(self, input_ids, attention_mask = None, decoder_input_ids = None, decoder_attention_mask = None, labels = None):  \n",
    "        return self.model(\n",
    "            input_ids, \n",
    "            attention_mask = attention_mask, \n",
    "            decoder_input_ids = decoder_input_ids, \n",
    "            decoder_attention_mask = decoder_attention_mask, \n",
    "            labels = labels\n",
    "        )\n",
    "    \n",
    "    \n",
    "    ''' Part 3: Configure optimizer and scheduler '''\n",
    "    def configure_optimizers(self): \n",
    "        # Optimizer\n",
    "        # I have no idea why to configure parameter this way \n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                # parameter with weight decay \n",
    "                'params': [param for name, param in model.named_parameters() if ('bias' not in name and 'LayerNorm.weight' not in name)], \n",
    "                'weight_decay': self.hparams['weight_decay'], \n",
    "            }, \n",
    "            {\n",
    "                'params': [param for name, param in model.named_parameters() if ('bias' in name or 'LayerNorm.weight' in name)], \n",
    "                'weight_decay': 0.0, \n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        self.optimizer = AdamW(optimizer_grouped_parameters, lr = self.hparams['learning_rate'])\n",
    "        \n",
    "        # Scheduler\n",
    "        # To create a scheduler with linear decay, we need to manually compute the number of training steps and pass it as an argument for the schduler \n",
    "        train_size = int(self.hparams['train_percentage'] * len(boTextsAll))\n",
    "        batch_size = self.hparams['batch_size']\n",
    "        num_processor = max(1, self.hparams['num_gpu'])\n",
    "        num_epoch = self.hparams['num_train_epochs']\n",
    "        total_training_steps = train_size // (batch_size * num_processor) * num_epoch\n",
    "        \n",
    "        # Create a scheduler for adjusting learning rate \n",
    "        self.lr_scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer = self.optimizer, \n",
    "            num_warmup_steps = self.hparams['warmup_steps'], \n",
    "            num_training_steps = total_training_steps\n",
    "        )\n",
    "        \n",
    "        self.lr_dict = {\n",
    "            'scheduler': self.lr_scheduler, # The LR schduler\n",
    "            'interval': 'step', # The unit of the scheduler's step size\n",
    "            'frequency': 1, # The frequency of the scheduler\n",
    "        }\n",
    "        \n",
    "        # Do constant rate this time\n",
    "        return [self.optimizer]# , [self.lr_dict]\n",
    "\n",
    "    \n",
    "    ''' Part 4.1: Training logic '''\n",
    "    def training_step(self, batch, batch_idx):         \n",
    "        loss = self._step(batch)\n",
    "        self.log('train_loss', loss)\n",
    "        # For monitoring purpose, log learning rate \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            if param_group['lr']:\n",
    "                self.log('learning_rate*e-4', param_group['lr'] * 1e4)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def _step(self, batch): \n",
    "        labels = batch['target_ids'] \n",
    "        labels[labels[:, ] == 0] = -100    # Change the pad id from 0 to -100, but I do not know why the example chooses to do so. I will comment it out for now\n",
    "        \n",
    "        outputs = self(\n",
    "            input_ids = batch['source_ids'], \n",
    "            attention_mask = batch['source_mask'], \n",
    "            labels = labels, \n",
    "            decoder_attention_mask = batch['target_mask']\n",
    "        )\n",
    "        \n",
    "        return outputs.loss\n",
    "\n",
    "    \n",
    "    ''' Part 4.2: Validation logic '''\n",
    "    def validation_step(self, batch, batch_idx):        \n",
    "        loss = self._step(batch)\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "        \n",
    "    ''' Part 4.3: Test logic '''\n",
    "    def test_step(self, batch, batch_idx): \n",
    "        loss = self._step(batch)\n",
    "        self.log('test_loss', loss)\n",
    "    \n",
    "    \n",
    "    ''' Part 5: Data loaders '''\n",
    "    def _get_dataloader(self, start_idx, end_idx): \n",
    "        dataset = MyDataset(\n",
    "            boTexts = boTextsAll[start_idx:end_idx], \n",
    "            enTexts = enTextsAll[start_idx:end_idx], \n",
    "            boTokenizer = self.hparams['boTokenizer'], \n",
    "            enTokenizer = self.hparams['enTokenizer'], \n",
    "            boMaxLen = self.hparams['max_input_len'], \n",
    "            enMaxLen = self.hparams['max_output_len']\n",
    "        )\n",
    "        \n",
    "        return DataLoader(dataset, batch_size = hparams['batch_size'])\n",
    "    \n",
    "    \n",
    "    def train_dataloader(self): \n",
    "        start_idx = 0\n",
    "        end_idx = int(self.hparams['train_percentage'] * len(boTextsAll))\n",
    "        return self._get_dataloader(start_idx, end_idx)\n",
    "    \n",
    "    \n",
    "    def val_dataloader(self): \n",
    "        start_idx = int(self.hparams['train_percentage'] * len(boTextsAll))\n",
    "        end_idx = int((self.hparams['train_percentage'] + self.hparams['val_percentage']) * len(boTextsAll))\n",
    "        return self._get_dataloader(start_idx, end_idx)\n",
    "    \n",
    "    \n",
    "    def test_dataloader(self): \n",
    "        start_idx = int((self.hparams['train_percentage'] + self.hparams['val_percentage']) * len(boTextsAll))\n",
    "        end_idx = len(boTextsAll)\n",
    "        return self._get_dataloader(start_idx, end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'boTokenizer': boTokenizer,\n",
    "    'enTokenizer': enTokenizer,\n",
    "    'pretrainedModelName': 't5-small', \n",
    "    'train_percentage': 0.95, \n",
    "    'val_percentage': 0.04, \n",
    "    'learning_rate': 1e-4, \n",
    "    'max_input_len': 100, \n",
    "    'max_output_len': 100, \n",
    "    'batch_size': 8, \n",
    "    'num_train_epochs': 10, \n",
    "    'num_gpu': 1, \n",
    "    'weight_decay': 0, \n",
    "    'warmup_steps': 0,  # For scheduler \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60 M  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36eb58cb89284824973cdfcee786f0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873ed6f25b9240c79de85aee94557fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0981d8f3c55f45b7beab3d5707f1cdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc2b5092f074f37ab76f80c1e6db44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed154ab7aaa477a97db73f4c69eb3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204a440bfa0a47d584322547b6343728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae4a6ede8ee409b8f2517562d10cecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7565c381fe04524bb80756db9c3c2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adeca974a39948d9aa9b88ab57f127e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dca71f3a4e44016ab488d960f3af688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c820201135c41c7a6753b127a8dec38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb77f796f678462d82237b3d10db5a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f553db0512548bdac7d01e61b1abde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'learning_rate*e-4': 1.0,\n",
      " 'test_loss': tensor(5.2341, device='cuda:0'),\n",
      " 'train_loss': tensor(5.3494, device='cuda:0'),\n",
      " 'val_loss': tensor(5.3414, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train_loss': 5.3494038581848145,\n",
       "  'learning_rate*e-4': 1.0,\n",
       "  'val_loss': 5.341426372528076,\n",
       "  'test_loss': 5.234098434448242}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_params = dict(\n",
    "    gpus = hparams['num_gpu'], \n",
    "    max_epochs = hparams['num_train_epochs'], \n",
    "    progress_bar_refresh_rate = 20, \n",
    ")\n",
    "\n",
    "model = T5FineTuner(hparams)\n",
    "\n",
    "trainer = pl.Trainer(**train_params)\n",
    "\n",
    "trainer.fit(model)\n",
    "\n",
    "# Save model for later use\n",
    "now = datetime.now()\n",
    "trainer.save_checkpoint('04_t5simple_bo_en_' + now.strftime(\"%Y-%m-%d--%H=%M=%S\") + '.ckpt')\n",
    "\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a previously saved model\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "modelLoaded = T5FineTuner.load_from_checkpoint(checkpoint_path='__04_t5simple_bo_en_2020-12-15--07=12=57.ckpt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tibetan Text: རྒྱལ་པོ་ཞེས་བྱ་བས་རྒྱལ་སྲིད་འབྱོར་པ་རྒྱས་པ་བདེ་བ་ལོ་ལེགས་པ་སྐྱེ་བོ་དང་མི་མང་པོས་གང་བ་བ\n",
      "ྱེད་དུ་བཅུག་གོ་\n",
      "\n",
      "Actual translation: under his rule the kingdom prospered and thrived crops were bountiful and the land teemed with animals and people\n",
      "\n",
      "Predicted translation: monks in this way the thusgone one correctly understands the knowledge of the path that leads to cessation as related to knowledge of what is impossible to be a tathagata an arhat a totally and completely awakened buddha possessed of insight and perfect conduct a sugata a knower of the world a tamer of persons a charioteer an unsurpassed one a teacher of humans and gods a teacher of humans and gods a teacher of humans and gods a teacher of humans and gods a teacher of humans and gods a teacher of humans and gods a teacher of\n",
      "==================================================\n",
      "\n",
      "Tibetan Text: དེས་དཔུང་གི་ཚོགས་ཡན་ལག་བཞི་པ་གླང་པོ་ཆེ་པའི་ཚོགས་དང་རྟ་པའི་ཚོགས་དང་ཤིང་རྟ་པའི་ཚོགས་དང་ད\n",
      "པུང་བུ་ཆུང་གི་ཚོགས་གོ་བསྐོན་ཏེ་ཡུལ་མ་ག་དཧའི་རྒྱལ་པོའི་ཁ་བ་མ་གཏོགས་པ་བཅོམ་ནས་ཕྱིར་ལྡོག་པར་བྱེད་དོ་\n",
      "\n",
      "Actual translation: he called up the four branches of his armed forcesthe elephant corps the cavalry the charioteer corps and the infantryand laid waste to all of magadha save rajagrha before returning\n",
      "\n",
      "Predicted translation: when the thusgone one is asked about the knowledge of the path that leads to cessation as related to knowledge of the world and the knowledge of the blessed one in the following way he will become a buddha for the sake of the world with its gods humans and asuras and so forth from the world with its gods humans and nonhumans who had been born into a family of great means prosperity and praised what the blessed one was residing in the world with its gods humans flowers and incense incense incense incense incense incense incense incense\n",
      "==================================================\n",
      "\n",
      "Tibetan Text: སུམ་ཅུ་རྩ་གསུམ་པའི་ལྷ་རྣམས་ཀྱི་ཁ་དོག་གི་མཐུ་བས་ལྷག་པའི་སྣང་བ་རྒྱ་ཆེན་པོས་ཁྱབ་པར་གྱུར་འ\n",
      "ཇིག་རྟེན་གྱི་འཇིག་རྟེན་གྱི་བར་གང་ན་ཉི་མ་དང་ཟླ་བ་འདི་ལྟར་རྫུ་འཕྲུལ་ཆེ་བ་འདི་ལྟར་མཐུ་ཆེ་བ་འདི་གཉིས་ཀྱི\n",
      "་འོད་དག་ཉམས་སུ་མི་མྱོང་བའི་མུན་པ་མུན་ནག་མུན་པར་བྱེད་པས་གནག་པར་གྱུར་པ་གང་དག་ཡིན་པ་དེ་དག་ཀྱང་དེའི་ཚེ་ན\n",
      "་སྣང་བ་རྒྱ་ཆེན་པོས་ཁྱབ་པར་གྱུར་ནས་སེམས་ཅན་གང་དག་དེར་སྐྱེས་པ་དག་གིས་རང་གི་ལག་པ་བརྐྱང་བ་ཡང་མི་མཐོང་བ་ད\n",
      "ེ་དག་གིས་ཀྱང་འོད་དེས་སེམས་ཅན་གཅིག་གིས་གཅིག་མཐོང་ནསཤེས་ལྡན་དག་སེམས་ཅན་གཞན་ཡང་འདིར་སྐྱེས་སོ་་ཤེས་ལྡན་ད\n",
      "ག་སེམས་ཅན་གཞན་ཡང་འདིར་སྐྱེས་སོ་ཞེས་ཤེས་པར་གྱུར་ཏོ་\n",
      "\n",
      "Actual translation: bathed in a vast light more luminous than the glow of the gods of the thirtythree so great was this miraculous manifestation it was as if the sun and moon shone in the gulf between worlds so great was its strength that darkness everywhere even the pitchblack darkness of dark places dark from never knowing the light of the sun and moon was filled with a vast light beings born in those places had never even seen so far as their outstretched hands yet by this light these beings saw one another and exclaimed you there there are others who\n",
      "\n",
      "Predicted translation: when the thusgone one is asked about the knowledge of the path that leads to cessation as related to the knowledge of the origin as related to knowledge of the world and the knowledge of the blessed one in the form of a hundred thousand beings who have been born in the form of a great being who has not been born in the form of a buddha will be able to see the blessed one he will become a buddha for the welfare of an immeasurable number of beings and so forth up until i will give you\n",
      "==================================================\n",
      "\n",
      "Tibetan Text: མ་མ་བརྒྱད་པོ་པང་ན་འཚོ་བའི་མ་མ་གཉིས་དང་ནུ་མ་སྣུན་པའི་མ་མ་གཉིས་དང་དྲི་མ་འཕྱི་བའི་མ་མ་གཉི\n",
      "ས་དང་རྩེ་འགྲོགས་ཀྱི་མ་མ་གཉིས་ལ་རྗེས་སུ་གཏད་དོ་་དེ་མ་མ་བརྒྱད་པོ་དག་གིས་འོ་མ་དང་ཞོ་དང་མར་དང་ཞུན་མར་དང་\n",
      "མར་གྱི་སྙིང་ཁུ་དང་གཞན་ཡང་ཡོ་བྱད་ཀྱི་བྱེ་བྲག་གཙོ་བོ་གཙོ་བོ་དག་གིས་བསྲིངས་པར་བྱེད་སྐྱེད་པར་བྱེད་ཅིང་རྫ\n",
      "ིང་ན་གནས་པའི་པདྨ་བཞིན་དུ་སྐྱེད་པར་བྱེད་དོ་\n",
      "\n",
      "Actual translation: was entrusted to eight nursemaids two to cuddle him two to breastfeed him two to change his diapers and two to play with him fortified with milk curd butter ghee cream and other nourishing foods he grew quickly shooting up like a lotus in a pond\n",
      "\n",
      "Predicted translation: when the thusgone one is asked about the knowledge of the path that leads to cessation as related to the knowledge of what is impossible in the following way i will be born into a family of great means prosperity and become a buddha for the sake of those beings who have not heard this dharma teaching from the world with its gods nagas yaksas gandharvas demigods garudas kimnaras mahoragas sakra lord of the gods nagas yaksas gandharvas demigods garudas kimnaras mahoragas humans and so forth do not make offerings to the blessed one how could it be such\n",
      "==================================================\n",
      "\n",
      "Tibetan Text: རྒྱལ་པོ་རྒྱལ་རིགས་སྤྱི་བོར་དབང་བསྐུར་བ་ལྗོངས་ཀྱི་དབང་ཕྱུག་མཐུ་དང་བརྩོན་འགྲུས་ཐོབ་པ་ས་ཆ\n",
      "ེན་པོའི་དཀྱིལ་འཁོར་མངོན་པར་རྒྱས་པར་བྱས་ཏེ་གནས་པ་རྣམས་ཀྱི་བཟོའི་གནས་དང་ལས་ཀྱི་གནས་ཐ་དད་པར་གྱུར་པ་གང་ད\n",
      "ག་ཡིན་པ་འདི་ལྟ་སྟེ་གླང་པོ་ཆེའི་གཉར་ཞོན་པ་དང་རྟ་ལ་ཞོན་པ་དང་ཤིང་རྟའི་ཐབས་དང་རལ་གྲིའི་ཐབས་དང་འཕོང་དང་ཕྱ\n",
      "ིར་བསྣུར་བ་དང་མདུན་དུ་བསྣུར་བ་དང་ལྕགས་ཀྱུས་སྒྱུར་ཐབས་དང་ཞགས་པ་གདབ་པ་དང་མདའ་བོ་ཆེ་འཕེན་ཐབས་དང་འཛིན་སྟ\n",
      "ངས་དང་གོམ་སྟངས་དང་ཐོར་ཚུགས་དང་གཅད་པ་དང་དྲལ་བ་དང་དབུག་པ་དང་གནས་ལྔ་པོ་འདི་ལྟ་སྟེ་རྒྱང་ནས་ཕོག་པ་དང་སྒྲ་\n",
      "གྲག་པར་ཕོག་པ་དང་གནད་དུ་ཕོག་པ་དང་མི་འཆོར་བར་ཕོག་པ་དང་ཚབས་ཆེ་བ་དེ་དག་ལ་ཡང་ཞུགས་ཤིང་བྱང་བར་གྱུར་ཏོ་\n",
      "\n",
      "Actual translation: he trained in and mastered those arts and skills needed to be crowned and anointed a ksatriya king to attain the might and dedication of a field marshal and to conquer and occupy the world riding on the neck of an elephant riding horseback charioteering swordsmanship archery advancing yielding wielding a hook throwing a lasso casting a spear and how to hold a weapon march tie a topknot slash quarter pierce and strike in five waysstriking from a distance striking a target using acoustic location striking a fatal blow striking without hesitation and striking\n",
      "\n",
      "Predicted translation: when the thusgone one is asked about the knowledge of the path that leads to cessation as related to the knowledge of what is impossible in the following way you should not be able to see the blessed one and so i will become a buddha for the world with its gods humans and nonhumans who has been born into the city of kapilavastu on the great city of kapilavastu by the lord of the world with its gods nagas yaksas gandharvas demigods garudas kimnaras mahoragas sakra lord of the gods nagas yaksas gandharvas gandharvas asuras garudas kimnaras mahoragas\n",
      "==================================================\n",
      "\n",
      "Tibetan Text: དེ་ཡང་རྒྱལ་པོ་རྒྱལ་རིགས་སྤྱི་བོར་དབང་བསྐུར་བ་ཡིན་ལ་\n",
      "\n",
      "Actual translation: he too has been crowned and anointed a ksatriya king\n",
      "\n",
      "Predicted translation: in the presence of the blessed one the thusgone one correctly understands the knowledge of the origin as related to knowledge of the path that leads to cessation as related to knowledge of what is impossible to be a mere convention just so the blessed one who has heard this dharma teaching on the path that leads to cessation as related to knowledge of what is impossible to be a mere convention just so it is impossible to be a mere convention just so the thusgone one correctly understands the knowledge of what is impossible to be a mere\n",
      "==================================================\n",
      "\n",
      "Tibetan Text: ལག་པ་འགྲམ་པ་ལ་བསྟད་ནས་སེམས་ཁོང་དུ་ཆུད་ཅིང་འདུག་འདུག་ནས་\n",
      "\n",
      "Actual translation: head in hands he sat and sat absorbed in thought\n",
      "\n",
      "Predicted translation: when the thusgone one is asked about the knowledge of the path that leads to cessation as related to the knowledge of what is impossible to be a tathagata an arhat a totally and completely awakened buddha possessed of insight and perfect conduct a sugata a knower of the world a tamer of persons a charioteer an unsurpassed one a teacher of humans and gods a teacher of humans and gods a teacher of humans and gods a teacher of humans and gods a teacher of humans and gods a teacher of humans in the world a teacher of\n",
      "==================================================\n",
      "\n",
      "Tibetan Text: ཡུལ་དང་སྲོག་ལ་གནོད་གྱུར་ན་་སྐྱེས་བུས་ཀུན་ཏུ་སྲོག་བསྲུང་བྱ་་བློ་ཡིས་གཉིས་ཀ་དཔྱད་བྱས་ན་་\n",
      "ཡུལ་ནི་ཡང་རྙེད་སྲོག་རྣམས་མིན་\n",
      "\n",
      "Actual translation: when land and life are threatened seek always to protect life when the wise look at both they see land but not life can be found again\n",
      "\n",
      "Predicted translation: when the thusgone one is asked about the knowledge of the path that leads to cessation as related to the knowledge of what is impossible in the following way you should not be able to see the blessed one i will become a buddha for the sake of all beings who have been born here in the world with its gods humans and nonhumans he has no doubt or whether they are free from fear and so on up to take birth in the ten directions at the seat of awakening there is no interest in the city of\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_idx = 0\n",
    "end_idx = 8\n",
    "\n",
    "testset = MyDataset(\n",
    "    boTexts = boTextsAll[start_idx:end_idx], \n",
    "    enTexts = enTextsAll[start_idx:end_idx], \n",
    "    boTokenizer = hparams['boTokenizer'], \n",
    "    enTokenizer = hparams['enTokenizer'], \n",
    "    boMaxLen = hparams['max_input_len'], \n",
    "    enMaxLen = hparams['max_output_len']\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(testset, batch_size = hparams['batch_size'])\n",
    "testit = iter(test_dataloader)\n",
    "\n",
    "# Take one batch from testset \n",
    "batch = next(testit)\n",
    "\n",
    "# Generate target ids\n",
    "outs = modelLoaded.model.generate(\n",
    "    batch['source_ids'].cuda(), \n",
    "    attention_mask = batch['source_mask'].cuda(), \n",
    "    use_cache = True, \n",
    "    decoder_attention_mask = batch['target_mask'], \n",
    "    max_length = hparams['max_output_len'], \n",
    "    num_beams = 4, \n",
    "    repetition_penalty = 2.5, \n",
    "    length_penalty = 0.6, \n",
    "    early_stopping = True, \n",
    ")\n",
    "\n",
    "pred_texts = [enTokenizer.decode(ids) for ids in outs.tolist()]\n",
    "source_texts = [boTokenizer.decode(ids) for ids in batch['source_ids'].tolist()]\n",
    "target_texts = [enTokenizer.decode(ids) for ids in batch['target_ids'].tolist()]\n",
    "\n",
    "for i in range(len(pred_texts)): \n",
    "    lines = textwrap.wrap(\"Tibetan Text:\\n%s\\n\" % source_texts[i], width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual translation: %s\" % target_texts[i])\n",
    "    print(\"\\nPredicted translation: %s\" % pred_texts[i])\n",
    "    print('=' * 50 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
