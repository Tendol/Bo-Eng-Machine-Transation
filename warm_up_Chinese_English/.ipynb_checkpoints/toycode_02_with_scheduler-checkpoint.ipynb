{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toycode for PyTorch-Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far I have bumped into many technical difficulties related to Pytorch-lightning and Tensorboard. In this notebook, I will use a simple model and dataset to experiment with different functionalities including: \n",
    "\n",
    "<ul>\n",
    "    <li>Tensorboard logging</li>\n",
    "    <li>Callback (Skip this part for now, as most callbacks (e.g. on_train_epoch_start) are self-explanatory)</li> \n",
    "    <li>Freeze parameters (A technique for speeding up training by updating less weights. Skip for now)</li>\n",
    "</ul>\n",
    "\n",
    "Other things I need to experiment \n",
    "\n",
    "<ul>\n",
    "    <li>Rouge metric and other metrics</li>\n",
    "    <li>Optimizer and scheduler</li>\n",
    "</ul>\n",
    "\n",
    "## Resources \n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"https://stackoverflow.com/questions/49542417/how-to-get-ipywidgets-working-in-jupyter-lab\">How to get ipywidget to work in Jupyter Lab</a></li>\n",
    "    <li><a href=\"https://pytorch-lightning.readthedocs.io/en/stable/\">PyTorch-lightning doc</a></li>\n",
    "    <li><a href=\"https://pytorch-lightning.readthedocs.io/en/stable/rapid_prototyping_templates.html\">Rapid prototyping</a></li>\n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from transformers import AdamW\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamp = 40000\n",
    "\n",
    "# Generate `nSamp` points\n",
    "X = (np.random.rand(nSamp, 5) ** 2 * 5).tolist()\n",
    "# Labels are the norms of `nSamp` points\n",
    "y = (np.sqrt(np.sum(np.square(X), axis = 1))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): \n",
    "    def __init__(self, X, y): \n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(y)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return {\n",
    "            'source': torch.tensor(X[idx]), \n",
    "            'target': torch.tensor([y[idx]]) # !! Even the target is a single number, we wrap it as vector\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(pl.LightningModule): \n",
    "    ''' Part 1: Define the architecture of model in init '''\n",
    "    def __init__(self, hparams):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(5, 10)\n",
    "        self.layer2 = nn.Linear(10, 8)\n",
    "        self.layer3 = nn.Linear(8, 1)\n",
    "        self.hparams = hparams \n",
    "        \n",
    "    ''' Part 2: Define the forward propagation '''\n",
    "    def forward(self, x): \n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "    ''' Part 3: Prepare optimizer and scheduler '''\n",
    "    def configure_optimizers(self): \n",
    "        optimizer = AdamW(self.parameters(), lr = self.hparams['learning_rate'])\n",
    "        return optimizer\n",
    "    \n",
    "    def optimizer_step(epoch=None, batch_idx=None, optimizer=None, optimizer_idx=None, optimizer_closure=None, on_tpu=None, using_native_amp=None, using_lbfgs=None): \n",
    "        \n",
    "    \n",
    "    ''' Part 4.1: Training logic '''\n",
    "    def training_step(self, batch, batch_idx): \n",
    "        X = batch['source']\n",
    "        y = batch['target']\n",
    "        y_hat = self(X)    # Calls forward function \n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        # We can log any metric that is (1) numeric (a single number); (2) aggregated / averaged from a batch\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    ''' Part 4.2: Validation logic '''\n",
    "    def validation_step(self, batch, batch_idx): \n",
    "        X = batch['source']\n",
    "        y = batch['target']\n",
    "        y_hat = self(X)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "    ''' Part 4.3: Test logic '''\n",
    "    def test_step(self, batch, batch_idx): \n",
    "        X = batch['source']\n",
    "        y = batch['target']\n",
    "        y_hat = self(X)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('test_loss', loss)\n",
    "        \n",
    "    ''' Part 5: Data loaders '''\n",
    "    def train_dataloader(self): \n",
    "        dataset = MyDataset(X[:int(0.7 * nSamp)], y[:int(0.7 * nSamp)])\n",
    "        return DataLoader(dataset, batch_size = hparams['batch_size'])\n",
    "    \n",
    "    def val_dataloader(self): \n",
    "        dataset = MyDataset(X[int(0.7 * nSamp):int(0.9 * nSamp)], y[int(0.7 * nSamp):int(0.9 * nSamp)])\n",
    "        return DataLoader(dataset, batch_size = hparams['batch_size'])\n",
    "    \n",
    "    def test_dataloader(self): \n",
    "        dataset = MyDataset(X[int(0.9 * nSamp):], y[int(0.9 * nSamp):])\n",
    "        return DataLoader(dataset, batch_size = hparams['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'learning_rate': 3e-4, \n",
    "    'batch_size': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type   | Params\n",
      "----------------------------------\n",
      "0 | layer1 | Linear | 60    \n",
      "1 | layer2 | Linear | 88    \n",
      "2 | layer3 | Linear | 9     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a060cacc9eb441be8ab4b06658c220ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445a0f175694494e963f8cf8bd39acc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time: 17.748871326446533s\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(hparams)\n",
    "trainer = pl.Trainer(gpus = 1, max_epochs = 2, progress_bar_refresh_rate = 20)\n",
    "\n",
    "start = time.time()\n",
    "trainer.fit(model)\n",
    "end = time.time()\n",
    "print(f'Total time: {end - start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa691669aaf94e1bbcc2be0f938c53e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(0.0777, device='cuda:0'),\n",
      " 'train_loss': tensor(0.0691, device='cuda:0'),\n",
      " 'val_loss': tensor(0.0777, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train_loss': 0.0690513551235199,\n",
       "  'val_loss': 0.07772146910429001,\n",
       "  'test_loss': 0.07772146910429001}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 2.0, 2.0, 3.0] has actual norm 4.358898943540674, predicted 4.635162353515625\n",
      "[0.024761101161934224, 2.3756007526008225, 0.03204466241353774, 0.011200267567321263, 1.2546817214823693] has actual norm 2.6869072511891967, predicted 2.616715431213379\n"
     ]
    }
   ],
   "source": [
    "x1 = [1.,1.,2.,2.,3.]\n",
    "x2 = X[0]\n",
    "\n",
    "print(f'{x1} has actual norm {np.sqrt(np.sum(np.square(x1)))}, predicted {model(torch.tensor(x1).to(\"cuda\"))[0]}')\n",
    "print(f'{x2} has actual norm {np.sqrt(np.sum(np.square(x2)))}, predicted {model(torch.tensor(x2).to(\"cuda\"))[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 29172), started 14:52:57 ago. (Use '!kill 29172' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-902d64b03f76a378\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-902d64b03f76a378\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
