## Files 

* `data_preprocess.py` - code to clean, and tokenize the data using sentencePiece 
* `bo.model` - sentencePiece tokenizer model for Tibetan 
* `en.model` - sentencePiece tokenizer model for English 